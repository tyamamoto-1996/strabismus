{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradCAMによる特徴可視化(Resnet18/50)",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyamamoto-1996/strabismus/blob/master/GradCAM%E3%81%AB%E3%82%88%E3%82%8B%E7%89%B9%E5%BE%B4%E5%8F%AF%E8%A6%96%E5%8C%96(Resnet18_50).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbsPKUW7FRHa",
        "colab_type": "text"
      },
      "source": [
        "#GradCam\n",
        "参考： https://github.com/eclique/pytorch-gradcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFdTGKtC77b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torch import nn\n",
        "from torchvision import models, transforms\n",
        "\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import glob\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ili7yBRc8aoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "フォルダ構成\n",
        "---dataset_all.zip-----train-----Cont\n",
        "                   |          |--Exte\n",
        "                   |          |--Inte\n",
        "                   |\n",
        "                   |---val-------Cont\n",
        "                              |--Exte\n",
        "                              |--Inte\n",
        "\n",
        "My Drive---Deep_learning-----test_RN18/50.pth\n",
        "                          |--synset_words.txt\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#dataset.zipを解凍\n",
        "\n",
        "!date -R\n",
        "!unzip -qq drive/My\\ Drive/dataset_all.zip\n",
        "!date -R\n",
        "!ls\n",
        "\n",
        "#パスの設定\n",
        "PATH = '/content/drive/My Drive/Deep_learning/test_RN18.pth'\n",
        "\n",
        "#model = models.vgg19(pretrained=True)\n",
        "model = models.resnet18(pretrained=True)\n",
        "#model = models.resnet50(pretrained=True)\n",
        "#model = models.densenet201(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfk69N-S8FN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Opens image from disk, normalizes it and converts to tensor\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                          std=[0.229, 0.224, 0.225]),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXzrDwzOBUdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyBVD2omBW2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Given label number returns class name\n",
        "def get_class_name(c):\n",
        "    labels = np.loadtxt('/content/drive/My Drive/Deep_learning/synset_words.txt', str, delimiter='\\t')\n",
        "    return ' '.join(labels[c].split(',')[0].split()[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1msc_em1BgUA",
        "colab_type": "text"
      },
      "source": [
        "#Load model\n",
        "Here, model is split into two parts: feature extractor and classifier. Provided is the implementation for ResNet/VGG/DenseNet architechtures.\n",
        "\n",
        "Here, Flatten layer is being built in in the model as well. In PyTorch implementation flattenning is done in the forward pass, but we need it as a separate layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Hf7NGSBggx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの設定\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "# 重みロード\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# Split model in two parts\n",
        "arch = model.__class__.__name__\n",
        "if arch == 'ResNet':\n",
        "    features_fn = nn.Sequential(*list(model.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "    classifier_fn = nn.Sequential(*(list(model.children())[-2:-1] + [Flatten()] + list(model.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        "elif arch == 'VGG':\n",
        "    features_fn = nn.Sequential(*list(model.features.children())[:-1])\n",
        "    classifier_fn = nn.Sequential(*(list(model.features.children())[-1:] + [Flatten()] + list(model.classifier.children())))\n",
        "elif arch == 'DenseNet':\n",
        "    features_fn = model.features\n",
        "    classifier_fn = nn.Sequential(*([nn.AvgPool2d(7, 1), Flatten()] + [model.classifier]))\n",
        "\n",
        "#評価モードにする    \n",
        "model = model.eval()\n",
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9zLuCFKdQjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ネットワークの確認\n",
        "from torchsummary import summary\n",
        "\n",
        "features_fn = features_fn.cuda()\n",
        "summary(features_fn, (3,224,224))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a40b91C-fr56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classifier_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kJayFCMC9VK",
        "colab_type": "text"
      },
      "source": [
        "#GradCam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM9W8p4WC9dH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    print(c)\n",
        "    print(c_score)\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYKAVE7KCfeQ",
        "colab_type": "text"
      },
      "source": [
        "#1枚だけ実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibHbrnXH7tY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#画像のパスを指定\n",
        "img_path = '/content/val/Exte/e1078.jpg'\n",
        "img_tensor = read_tensor(img_path) #ここに前処理も含まれる\n",
        "#Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "pp, cc = torch.topk(nn.Softmax(dim=1)(model(img_tensor.to(device))), 1)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "#pとcを対にして入力\n",
        "for i, (p, c) in enumerate(zip(pp[0], cc[0])):\n",
        "    #グラフを1行3列に並べたうちのi番目\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "    img = Image.open(img_path)\n",
        "    #TensorをImageに変換\n",
        "    sal = Image.fromarray(sal)\n",
        "    sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "    #plt.title('')\n",
        "    plt.title('{}: {:.1f}%'.format(get_class_name(c), 100*float(p)))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAOfpbbqJleh",
        "colab_type": "text"
      },
      "source": [
        "#フォルダ内の画像全てに実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEjgG-TblTaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#画像のパスを指定\n",
        "img_dr = glob.glob('/content/val/*/*')\n",
        "\n",
        "for img_path in img_dr:\n",
        "    img_tensor = read_tensor(img_path) #ここに前処理も含まれる\n",
        "    #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "    pp, cc = torch.topk(nn.Softmax(dim=1)(model(img_tensor.to(device))), 1)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    #pとcを対にして入力\n",
        "    for i, (p, c) in enumerate(zip(pp[0], cc[0])):\n",
        "        #グラフを1行3列に並べたうちのi番目\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "        img = Image.open(img_path)\n",
        "        #TensorをImageに変換\n",
        "        sal = Image.fromarray(sal)\n",
        "        sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "        #plt.title('')\n",
        "        plt.title('{}: {:.1f}%'.format(get_class_name(c), 100*float(p)))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "        plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}